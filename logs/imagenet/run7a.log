GPU: NVIDIA A10G
Total GPU memory: 23.7 GB
Allocated memory: 0.0 GB
Reserved memory: 0.0 GB
======================================================================
ğŸš€ ImageNet Training Pipeline - ResNet50 on Tiny ImageNet
======================================================================

[STEP 1/6] Checking dataset...

[STEP 2/6] Loading dataset and creating data loaders...
  - Batch size: 368, num_workers: 16
âœ… Using cache directory: /Imagenet/datasets_cache
Sample cache file: /Imagenet/datasets_cache/ILSVRC___imagenet-1k/default/0.0.0/49e2ee26f3810fb5a7536bbf732a7b07389a47b5/imagenet-1k-train-00000-of-00267.arrow
Mode for train transforms=finetune
âœ… Saved augmentation preview to aug_preview_finetune.png
âœ“ Train loader: 1281167 images, 3482 batches
âœ“ Val loader: 50000 images, 136 batches

[STEP 3/6] Skipping dataset inspection (set inspect_data=True to enable)
ğŸ” Profiling DataLoader speed before training ...
ğŸ” DataLoader profiling: 200 batches
â±ï¸  Average batch load time: 0.3298 sec
âš¡ Approx. samples/sec (per worker): 69.7
âœ… Avg. DataLoader batch time: 0.3298s


[STEP 4/6] Initializing ResNet50 model...
  - Device: cuda
âœ“ Model created: ResNet50
  - Total parameters: 25,557,032
  - Trainable parameters: 25,557,032

[STEP 5/6] Setting up optimizer and LR scheduler...
âœ“ Optimizer: SGD (lr=0.1, momentum=0.9, weight_decay=0.0001), nesterov=True
  - Max LR: 0.1
  - Total steps: 21750
âœ“ LR Scheduler: CosineAnnealingLR with warmup of 2 epochs

[STEP 6/6] Starting training...
======================================================================
Starting fresh scheduler for fine-tuning.
Loaded /Data/checkpoints/Run7-finetuning-highlr/run5-epoch89.pth for finetuning run, without loading optimizer/scheduler/scaler states

======================================================================
ğŸ“Š EPOCH 1/25
======================================================================

ğŸ”„ Training...
Cutmix probability for epoch 1=0.0996057350657239
[Debug setup] Diagnostics will run at batches: [0, 348, 696, 1044, 1392, 1741, 2089, 2437, 2785, 3133]
[Debug] Input mean=-0.0282, std=1.2402, min=-2.1179, max=2.6400
[Debug] Device check: model=cuda:0, data=cuda:0
[Debug] Batch shape: (368, 3, 224, 224)
[Debug] Label range: 0â€“997
step 0 LR=0.010000 batch_loss=2.5791
step 1 LR=0.010052 batch_loss=4.1704
step 2 LR=0.010103 batch_loss=2.4021
step 3 LR=0.010155 batch_loss=3.3778
step 4 LR=0.010207 batch_loss=3.1217

ğŸ” Validating...

Val set: Avg loss: 2.4964, Accuracy: 33279/50000 (66.56%)


ğŸ“ˆ Epoch 1 Summary:
  - Train Loss: 2.7770
  - Train Acc: 30.87%
  - Val Loss: 2.4964
  - Val Acc: 66.56%
  - Current LR: 0.055052
Validation loss improved to 2.4964. Saving model weights to /Data/checkpoints/Run7-finetuning-highlr/best.pth
âœ… Checkpoint saved to /Data/checkpoints/Run7-finetuning-highlr/best.pth
Saving epoch weights: /Data/checkpoints/Run7-finetuning-highlr/epoch-1.pth
âœ… Checkpoint saved to /Data/checkpoints/Run7-finetuning-highlr/epoch-1.pth
Time taken for epoch 1: 0:38:09.049263

======================================================================
ğŸ“Š EPOCH 2/25
======================================================================

ğŸ”„ Training...
Cutmix probability for epoch 2=0.09842915805643156
[Debug setup] Diagnostics will run at batches: [0, 348, 696, 1044, 1392, 1741, 2089, 2437, 2785, 3133]
[Debug] Input mean=-0.0049, std=0.9432, min=-2.1179, max=2.6400
[Debug] Device check: model=cuda:0, data=cuda:0
[Debug] Batch shape: (368, 3, 224, 224)
[Debug] Label range: 3â€“989
step 0 LR=0.055052 batch_loss=2.7721
step 1 LR=0.055103 batch_loss=2.6765
step 2 LR=0.055155 batch_loss=2.8160
step 3 LR=0.055207 batch_loss=2.7949
step 4 LR=0.055259 batch_loss=2.8138

ğŸ” Validating...

Val set: Avg loss: 3.3703, Accuracy: 25465/50000 (50.93%)


ğŸ“ˆ Epoch 2 Summary:
  - Train Loss: 4.9220
  - Train Acc: 26.94%
  - Val Loss: 3.3703
  - Val Acc: 50.93%
  - Current LR: 0.100000
Saving epoch weights: /Data/checkpoints/Run7-finetuning-highlr/epoch-2.pth
âœ… Checkpoint saved to /Data/checkpoints/Run7-finetuning-highlr/epoch-2.pth
Time taken for epoch 2: 0:37:25.556324

======================================================================
ğŸ“Š EPOCH 3/25
======================================================================

ğŸ”„ Training...
Cutmix probability for epoch 3=0.09648882429441258
[Debug setup] Diagnostics will run at batches: [0, 348, 696, 1044, 1392, 1741, 2089, 2437, 2785, 3133]
